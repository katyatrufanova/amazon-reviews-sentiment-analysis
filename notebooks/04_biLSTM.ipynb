{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTzqYkzCcqe5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AueIkbNgp9d-",
        "outputId": "3cadc36d-8c14-4a09-a512-78c5eadc54f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/ML/Amazon_Unlocked_Mobile.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "z3jjmcNglnXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "pVqVyaK7lsJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = \" \".join([word for word in text.split() if word not in stopwords.words('english')])\n",
        "    return text"
      ],
      "metadata": {
        "id": "Y50PvFyglt7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Hh5Dj5qKER",
        "outputId": "c0939698-0ac0-4edf-f206-7a2f283f900c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['CleanedReviews'] = data['Reviews'].apply(clean_text)"
      ],
      "metadata": {
        "id": "ltUB5_0olvim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding\n",
        "def sentiment(rating):\n",
        "    if rating < 3:\n",
        "        return 'negative'\n",
        "    elif rating == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'positive'"
      ],
      "metadata": {
        "id": "Wxa9RweUly_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sentiment'] = data['Rating'].apply(sentiment)"
      ],
      "metadata": {
        "id": "jtZ4VCnTl17W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "X = data['CleanedReviews']\n",
        "y = data['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XlSoS13Il4UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_len = max([len(seq) for seq in X_train_seq])\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len)"
      ],
      "metadata": {
        "id": "MZ8nxU6sl7Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained word embeddings (GloVe)\n",
        "embedding_dict = {}\n",
        "with open('/content/drive/MyDrive/ML/glove.6B.100d.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], 'float32')\n",
        "        embedding_dict[word] = vector\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "\n",
        "# Iterate over each word in the tokenizer's word index\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    # Get the corresponding word vector from the embedding dictionary\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    # If the word vector exists, add it to the embedding matrix\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "dK-UUc2Yl9Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bidirectional LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(128)))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BtHsyToHmAaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "OqrpsvNdmCnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(X_train_padded, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lcw_x_PrmEnB",
        "outputId": "4336a33f-19ec-4c21-cbeb-341b7dce5007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6687/6687 [==============================] - 1083s 160ms/step - loss: 0.4539 - accuracy: 0.8343 - val_loss: 0.4332 - val_accuracy: 0.8437\n",
            "Epoch 2/10\n",
            "6687/6687 [==============================] - 1115s 167ms/step - loss: 0.3869 - accuracy: 0.8598 - val_loss: 0.3684 - val_accuracy: 0.8672\n",
            "Epoch 3/10\n",
            "6687/6687 [==============================] - 1111s 166ms/step - loss: 0.3436 - accuracy: 0.8769 - val_loss: 0.3374 - val_accuracy: 0.8793\n",
            "Epoch 4/10\n",
            "6687/6687 [==============================] - 1112s 166ms/step - loss: 0.3020 - accuracy: 0.8938 - val_loss: 0.3181 - val_accuracy: 0.8898\n",
            "Epoch 5/10\n",
            "6687/6687 [==============================] - 1108s 166ms/step - loss: 0.2631 - accuracy: 0.9103 - val_loss: 0.3076 - val_accuracy: 0.8970\n",
            "Epoch 6/10\n",
            "6687/6687 [==============================] - 1113s 166ms/step - loss: 0.2269 - accuracy: 0.9242 - val_loss: 0.3123 - val_accuracy: 0.9016\n",
            "Epoch 7/10\n",
            "6687/6687 [==============================] - 1116s 167ms/step - loss: 0.1971 - accuracy: 0.9365 - val_loss: 0.2967 - val_accuracy: 0.9087\n",
            "Epoch 8/10\n",
            "6687/6687 [==============================] - 1109s 166ms/step - loss: 0.1687 - accuracy: 0.9461 - val_loss: 0.3025 - val_accuracy: 0.9122\n",
            "Epoch 9/10\n",
            "6687/6687 [==============================] - 1124s 168ms/step - loss: 0.1456 - accuracy: 0.9541 - val_loss: 0.3135 - val_accuracy: 0.9153\n",
            "Epoch 10/10\n",
            "6687/6687 [==============================] - 1116s 167ms/step - loss: 0.1270 - accuracy: 0.9612 - val_loss: 0.3259 - val_accuracy: 0.9181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test and evaluate the model\n",
        "y_pred = model.predict(X_test_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_encoded, y_pred_classes, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjanMcJnmGcb",
        "outputId": "5ab19882-74a4-4606-898f-10252e27503e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2090/2090 [==============================] - 125s 59ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.90      0.89     15609\n",
            "     neutral       0.72      0.55      0.63      5228\n",
            "    positive       0.95      0.97      0.96     46030\n",
            "\n",
            "    accuracy                           0.92     66867\n",
            "   macro avg       0.85      0.81      0.82     66867\n",
            "weighted avg       0.91      0.92      0.91     66867\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "model_without_glove = Sequential()\n",
        "model_without_glove.add(Embedding(vocab_size, 100, input_length=max_len))\n",
        "model_without_glove.add(Bidirectional(LSTM(128)))\n",
        "model_without_glove.add(Dense(3, activation='softmax'))\n",
        "model_without_glove.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FOoixvpumTGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history_without_glove = model_without_glove.fit(X_train_padded, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "OLnLTgylmTZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db6e510-c42c-4962-851d-f720c0fb4078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6687/6687 [==============================] - 1320s 196ms/step - loss: 0.3734 - accuracy: 0.8669 - val_loss: 0.3146 - val_accuracy: 0.8893\n",
            "Epoch 2/10\n",
            "6687/6687 [==============================] - 1174s 176ms/step - loss: 0.2628 - accuracy: 0.9093 - val_loss: 0.2839 - val_accuracy: 0.9035\n",
            "Epoch 3/10\n",
            "6687/6687 [==============================] - 1168s 175ms/step - loss: 0.1996 - accuracy: 0.9332 - val_loss: 0.2773 - val_accuracy: 0.9104\n",
            "Epoch 4/10\n",
            "6687/6687 [==============================] - 1163s 174ms/step - loss: 0.1536 - accuracy: 0.9502 - val_loss: 0.2868 - val_accuracy: 0.9144\n",
            "Epoch 5/10\n",
            "6687/6687 [==============================] - 1159s 173ms/step - loss: 0.1207 - accuracy: 0.9622 - val_loss: 0.3037 - val_accuracy: 0.9149\n",
            "Epoch 6/10\n",
            "6687/6687 [==============================] - 1162s 174ms/step - loss: 0.0974 - accuracy: 0.9706 - val_loss: 0.3228 - val_accuracy: 0.9203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_without_glove = model_without_glove.predict(X_test_padded)\n",
        "y_pred_classes_without_glove = np.argmax(y_pred_without_glove, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqKGPQNDTM-N",
        "outputId": "faf0fc0b-7fcc-410d-e322-91c5952c3c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2090/2090 [==============================] - 128s 61ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report without GloVe embeddings (baseline):\\n\", classification_report(y_test_encoded, y_pred_classes_without_glove, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r8i0g3yTSS4",
        "outputId": "1d66c04b-c403-4004-be91-4b7dde2773b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report without GloVe embeddings (baseline):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.88      0.89     15609\n",
            "     neutral       0.70      0.60      0.65      5228\n",
            "    positive       0.95      0.97      0.96     46030\n",
            "\n",
            "    accuracy                           0.92     66867\n",
            "   macro avg       0.85      0.82      0.83     66867\n",
            "weighted avg       0.92      0.92      0.92     66867\n",
            "\n"
          ]
        }
      ]
    }
  ]
}